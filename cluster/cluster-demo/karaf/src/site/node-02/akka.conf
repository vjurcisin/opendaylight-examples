
odl-cluster-data {
  bounded-mailbox {
    mailbox-type = "org.opendaylight.controller.cluster.common.actor.MeteredBoundedMailbox"
    mailbox-capacity = 1000
    mailbox-push-timeout-time = 100ms
  }

  metric-capture-enabled = true

  akka {
    loglevel = "INFO"
    loggers = ["akka.event.slf4j.Slf4jLogger"]
    logger-startup-timeout = 300s

    actor {
      provider = "akka.cluster.ClusterActorRefProvider"
      serializers {
        java = "akka.serialization.JavaSerializer"
        proto = "akka.remote.serialization.ProtobufSerializer"
        readylocal = "org.opendaylight.controller.cluster.datastore.messages.ReadyLocalTransactionSerializer"
      }

      serialization-bindings {
        "com.google.protobuf.Message" = proto
        "org.opendaylight.controller.cluster.datastore.messages.ReadyLocalTransaction" = readylocal
      }

      default-dispatcher {
        # Setting throughput to 1 makes the dispatcher fair. It processes 1 message from
        # the mailbox before moving on to the next mailbox
        throughput = 1
      }

      default-mailbox {
        # When not using a BalancingDispatcher it is recommended that we use the SingleConsumerOnlyUnboundedMailbox
        # as it is the most efficient for multiple producer/single consumer use cases
        mailbox-type="akka.dispatch.SingleConsumerOnlyUnboundedMailbox"
      }
    }
    remote {
      log-remote-lifecycle-events = off
      netty.tcp {
        hostname = "192.168.56.102"
        port = 2550
        maximum-frame-size = 419430400
        send-buffer-size = 52428800
        receive-buffer-size = 52428800
      }
    }

    cluster {
      seed-nodes = [
        "akka.tcp://opendaylight-cluster-data@192.168.56.101:2550",
        "akka.tcp://opendaylight-cluster-data@192.168.56.102:2550",
      	"akka.tcp://opendaylight-cluster-data@192.168.56.103:2550"
      ]
      
      seed-node-timeout = 12s

      auto-down-unreachable-after = 300s

      roles = [
        "member-2"
      ]

      pub-sub {
        # Actor name of the mediator actor, /system/distributedPubSubMediator
        name = distributedPubSubMediator

        # Start the mediator on members tagged with this role.
        # All members are used if undefined or empty.
        role = ""

        # The routing logic to use for 'Send'
        # Possible values: random, round-robin, broadcast
        routing-logic = random

        # How often the DistributedPubSubMediator should send out gossip information
        gossip-interval = 1s

        # Removed entries are pruned after this duration
        removed-time-to-live = 120s

        # Maximum number of elements to transfer in one message when synchronizing the registries.
        # Next chunk will be transferred in next round of gossip.
        max-delta-elements = 3000

        # The id of the dispatcher to use for DistributedPubSubMediator actors.
        # If not specified default dispatcher is used.
        # If specified you need to define the settings of the actual dispatcher.
        use-dispatcher = ""
      }

      singleton {
        # The actor name of the child singleton actor.
        singleton-name = "the-singleton"

        # Singleton among the nodes tagged with specified role.
        # If the role is not specified it's a singleton among all nodes in the cluster.
        role = ""

        # When a node is becoming oldest it sends hand-over request to previous oldest,
        # that might be leaving the cluster. This is retried with this interval until
        # the previous oldest confirms that the hand over has started or the previous
        # oldest member is removed from the cluster (+ akka.cluster.down-removal-margin).
        hand-over-retry-interval = 1s

        # The number of retries are derived from hand-over-retry-interval and
        # akka.cluster.down-removal-margin (or ClusterSingletonManagerSettings.removalMargin),
        # but it will never be less than this property.
        min-number-of-hand-over-retries = 10
      }

      singleton-proxy {
        # The actor name of the singleton actor that is started by the ClusterSingletonManager
        singleton-name = "the-singleton"

        # The role of the cluster nodes where the singleton can be deployed.
        # If the role is not specified then any node will do.
        role = ""

        # Interval at which the proxy will try to resolve the singleton instance.
        singleton-identification-interval = 1s

        # If the location of the singleton is unknown the proxy will buffer this
        # number of messages and deliver them when the singleton is identified.
        # When the buffer is full old messages will be dropped when new messages are
        # sent via the proxy.
        # Use 0 to disable buffering, i.e. messages will be dropped immediately if
        # the location of the singleton is unknown.
        # Maximum allowed buffer size is 10000.
        buffer-size = 1000
      }

    }

    persistence {
      # By default the snapshots/journal directories live in KARAF_HOME. You can choose to put it somewhere else by
      # modifying the following two properties. The directory location specified may be a relative or absolute path. 
      # The relative path is always relative to KARAF_HOME.

      # snapshot-store.local.dir = "target/snapshots"
      # journal.leveldb.dir = "target/journal"

    }

    extensions = ["akka.cluster.pubsub.DistributedPubSub"]

  }
}

odl-cluster-rpc {
  bounded-mailbox {
    mailbox-type = "org.opendaylight.controller.cluster.common.actor.MeteredBoundedMailbox"
    mailbox-capacity = 1000
    mailbox-push-timeout-time = 100ms
  }

  metric-capture-enabled = true

  akka {
    loglevel = "INFO"
    loggers = ["akka.event.slf4j.Slf4jLogger"]
    logger-startup-timeout = 300s

    actor {
      provider = "akka.cluster.ClusterActorRefProvider"

    }
    remote {
      log-remote-lifecycle-events = off
      netty.tcp {
        hostname = "192.168.56.102"
        port = 2551
        maximum-frame-size = 419430400
        send-buffer-size = 52428800
        receive-buffer-size = 52428800
      }
    }

    cluster {
      seed-nodes = [
        "akka.tcp://odl-cluster-rpc@192.168.56.101:2551",
        "akka.tcp://odl-cluster-rpc@192.168.56.102:2551",
        "akka.tcp://odl-cluster-rpc@192.168.56.103:2551"
      ]

      auto-down-unreachable-after = 300s
    }
  }
}
